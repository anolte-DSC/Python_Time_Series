{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "031778c0-ae92-4eea-8a18-4c18c67118d4",
   "metadata": {},
   "source": [
    "<img src=\"../Images/DSC_Logo.png\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ea209f-eeab-4bef-ab36-578ab1c2b1da",
   "metadata": {},
   "source": [
    "# Plancton Assemblage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f463414-1283-43f7-a79b-8e302fc35da2",
   "metadata": {},
   "source": [
    "![core](../Images/core_foraminifera.png)\n",
    "\n",
    "*Image modified from Northwestern University and T. Boeschen, GEOMAR*\n",
    "\n",
    "This notebook analyzes a dataset detailing plankton assemblage changes over the past 24,000 years, correlating these shifts with climatic data. The dataset includes three CSV files: planktonic foraminifera time series, metadata, and climatic time series data. Principal Component Analysis (PCA) and Generalized Additive Models (GAM) are used to explore biodiversity trends and responses to climate change. \n",
    "\n",
    "**Original dataset and code:** Strack, T., Jonkers, L., Rillo, M. C., Baumann, K.-H., Hillebrand, H., & Kucera, M.: Harmonized data and R code for \"Coherent response of zoo- and phytoplankton assemblages to global warming since the Last Glacial Maximum\" [Data set]. Zenodo. doi:10.5281/zenodo.10803875,                        retrieved on August 12, 2024.\n",
    "\n",
    "**Related publication:** Strack, T., Jonkers, L., C. Rillo, M., Baumann, K.-H., Hillebrand, H., and Kucera, M.: Coherent response of zoo‚Äê and phytoplankton assemblages to global warming since the Last Glacial Maximum, Global Ecol Biogeogr, 33, e13841, doi:10.1111/geb.13841,             2024.\n",
    "\n",
    "Original data and code were modified for this notebook. The analyses presented here may not align with those published."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111b8ec0-eb69-407a-97e8-421462c8777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97340653-049e-4c0e-b9b3-21e17079ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_ts = pd.read_csv('../Datasets/planctonic_foraminifera/pf_data.csv') # planctonic foraminifera time series data\n",
    "core_list = pd.read_csv('../Datasets/planctonic_foraminifera/core_list.csv') # planctonic foraminifera metadata\n",
    "GMST = pd.read_csv('../Datasets/planctonic_foraminifera/GMST.csv') # climatic time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47125952",
   "metadata": {},
   "source": [
    "## 1. Prepare and Investigate Time Series and Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb697679-bb00-4bdf-9523-a4663459315d",
   "metadata": {},
   "source": [
    "## 1.1 Time Series Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630a9bfb-8cb0-4d8c-8a06-d8200982465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_ts.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0deecf9b-6171-485d-8690-c9dd9c46e0d6",
   "metadata": {},
   "source": [
    "There are multiple species per ID and time variables (age that relates to depth):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370e726d-899c-43c6-876c-98d646658a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_ts.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa19d6c-4fa3-487d-8078-8e388ab70dd7",
   "metadata": {},
   "source": [
    "List of unique IDs that represent the individual samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e6f3a3-9d32-4f03-9599-f0c695cd8223",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_list = pf_ts['ID'].unique()\n",
    "print(ID_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef40d1e-0eb0-4ba0-9a17-7821b48dd79f",
   "metadata": {},
   "source": [
    "## 1.2 Create wide-format datasets for each ID and store them in a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3222ae-e22c-4727-b540-3691a1786b4f",
   "metadata": {},
   "source": [
    "In wide format, each species (defined by the 'Species' column) becomes a separate column, allowing for quick and direct access to individual species' abundance data. This makes it easier to perform calculations, comparisons, and visualizations on specific variables without needing to filter or reshape the dataset continuously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94708d5f-3c9a-4e9c-83f9-0a87040dc461",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_ts_wide = {}\n",
    "\n",
    "for i in pf_ts['ID'].unique():\n",
    "    wide_i = pf_ts[pf_ts['ID'] == i].pivot_table(\n",
    "        index=['Depth_m', 'Age_kaBP'], \n",
    "        columns='Species', \n",
    "        values='Rel_abundance', \n",
    "        fill_value=0\n",
    "    )\n",
    "    pf_ts_wide[i] = wide_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003bfb7e-7527-4fe0-969a-f33bc592792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = '339-u1385_dinocyst'\n",
    "pf_ts_wide[ID].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596169e3-e4dd-46f0-bd19-45c2245b4977",
   "metadata": {},
   "source": [
    "## 1.3 Check Rel_abundance column for an example ID and time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f017b0e-7e0e-42a2-a521-ac1428cfc7d6",
   "metadata": {},
   "source": [
    "Select example ID and time via depth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0b31ff-efa1-448e-a5ff-643808863b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = '339-u1385_dinocyst'\n",
    "depth = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6b1a58-3d82-4e52-b21a-ce917a8f2abf",
   "metadata": {},
   "source": [
    "Check in the original (long format) data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eeb88a-d2d9-4eb0-8a72-0b80640ca2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_sum = pf_ts[(pf_ts['ID'] == ID) & (pf_ts['Depth_m'] == depth)]['Rel_abundance'].sum() \n",
    "print(f\"Long format sum: {long_sum * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e8f142-8f95-4fa4-a568-24e1c871b9fd",
   "metadata": {},
   "source": [
    "Check in the transformed (wide format) data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b09908b-9b1a-45ac-9bff-aa9c2eee739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_sum = pf_ts_wide[ID].loc[depth].sum().sum() \n",
    "print(f\"Wide format sum: {wide_sum * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f64c2f-cf3c-4da0-aa25-02ccc53a073c",
   "metadata": {},
   "source": [
    "## 1.4 Plot locations on map from metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fd8f7e-3f3c-4c2a-a103-d5e3f0ddb8ce",
   "metadata": {},
   "source": [
    "Load additional packages for plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff12a8a-ca3b-4f43-b384-b3697abe8eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a9a076-4e6d-4072-803f-3a67464b2ac4",
   "metadata": {},
   "source": [
    "Create a dictionary for colors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f348a970-ba7e-4e08-b6d0-18359c70b99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "foraminifera_colors = {\n",
    "    'planktonic foraminifera': '#9D9E9E',\n",
    "    'coccolithophore': '#36648B',\n",
    "    'dinocyst': '#CD950C'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bfc72c-5709-424f-9986-4216fd2db1d3",
   "metadata": {},
   "source": [
    "Create a geodataframe from the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5888ee7-806c-4c11-bab3-3749f910caef",
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = [Point(xy) for xy in zip(core_list['lon'], core_list['lat'])]\n",
    "gdf = gpd.GeoDataFrame(core_list, geometry=geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dd9145-296b-42c2-849f-8269b2742db5",
   "metadata": {},
   "source": [
    "Plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c8ede4-be23-47ba-bc64-b730674995e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4, 4), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "ax.add_feature(cfeature.LAND, edgecolor='black', color='lightgrey')\n",
    "ax.add_feature(cfeature.OCEAN, color='white')  # Set ocean color to white\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "\n",
    "for plankton_type, color in foraminifera_colors.items():\n",
    "    subset = gdf[gdf['Plankton'] == plankton_type]\n",
    "    subset.plot(ax=ax, marker='o', color=color, markersize=100, alpha=0.7, transform=ccrs.PlateCarree(), label=plankton_type.capitalize())\n",
    "\n",
    "ax.legend(title='Plankton Type', loc='upper center', bbox_to_anchor=(0.5, 1.2), ncol=3, fontsize=8, title_fontsize=8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b635196-10eb-448e-bf51-92d4bccecea5",
   "metadata": {},
   "source": [
    "## **Exercise 1: Dimensionality Reduction in Time Series**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31993298-8a36-4ad5-87db-4b16bb5f9434",
   "metadata": {},
   "source": [
    "The study utilized PCA to streamline species assemblage data at each site, emphasizing key temporal changes. By extracting the first principal component (PC1), the analysis captured the majority of variance, enabling an understanding of site-specific shifts in species composition over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36ab779-07e2-43dc-85e1-2a25c5a696f0",
   "metadata": {},
   "source": [
    "## 2. Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af504ec-c523-4783-8895-b212ad6a99a6",
   "metadata": {},
   "source": [
    "**Exercise:** Import functions for conducting PCA analysis with the standardized dataset from the `sklearn` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53e6760-b3b7-4f6b-b14e-5fa039855355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed9ba243-424f-4d01-aa71-33ba3e2294e2",
   "metadata": {},
   "source": [
    "## Workflow for a single ID:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148b6113-75f6-4f92-9bbf-c1eaa455dc82",
   "metadata": {},
   "source": [
    "**Exercise:** Get a list of all unique sample IDs in the original time series *pf_ts* and select a single ID, which you define as a new variable named *ID*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9610476d-8c2b-42a2-97f0-52d25bbbc387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a72ec478-55a6-4373-9e78-0dc7ef56c198",
   "metadata": {},
   "source": [
    "We retrieve the wide-format DataFrame for the given ID from the *pf_ts_wide* dictionary and name it *pf_ts_wide_i*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6634474-77fd-4879-a12a-6c12b125ddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_ts_wide_i = pf_ts_wide.get(ID)\n",
    "pf_ts_wide_i.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a923df-fa5a-4664-96d2-5ec51a691492",
   "metadata": {},
   "source": [
    "**Exercise:** Standardize the data before applying PCA. Name the standardized data *pf_ts_wide_i_scaled*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c23186-d018-41f3-b756-97cef564f0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3eb904c-a519-4113-adc6-bb1b0327dff8",
   "metadata": {},
   "source": [
    "**Exercise:** Apply the PCA to find five Principal Components (PCs). Save the resulting PC values as *pca_scores* and print it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1a8039-fe44-4b1f-893a-9dcc5ec6a72f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65d4990e-98a4-4aa9-a2d0-19813cff9a8e",
   "metadata": {},
   "source": [
    "**Exercise:** Extract the explained variance ratio from the PCA, save it as *evr* and print it. In addition, plot the explained variance ratio. How much variance is explained by the first PC alone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d556154c-eede-4812-8062-f9595bcbe20b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9d5f28-ddee-4cd9-9bc3-3052203640a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a47aca1-2258-4836-b5df-7a0c24841487",
   "metadata": {},
   "source": [
    "We create a DataFrame out of the *pca_scores* and the *evr* values that aligns with the time index of *pf_ts_wide_i* for analyzing how the PCs relate to time and time-dependend conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8885f283-ee62-4495-800e-f5112fc00915",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca_scores = pd.DataFrame(pca_scores, index=pf_ts_wide_i.index, columns=['PC1','PC2','PC3','PC4','PC5'])\n",
    "pca_scores['PC1_Var'] = evr[0]\n",
    "pca_scores['PC2_Var'] = evr[1]\n",
    "pca_scores['PC3_Var'] = evr[2]\n",
    "pca_scores['PC4_Var'] = evr[3]\n",
    "pca_scores['PC5_Var'] = evr[4]\n",
    "pca_scores.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4683a0b1-34b8-4313-a4e3-f70f6c45a8c8",
   "metadata": {},
   "source": [
    "We run the workflow in a function for every ID using only the first PC as in the orinal study:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256deba3-7592-4700-8145-dd3dcc23cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_analysis(df):\n",
    "\n",
    "    # Standardize the data before applying PCA\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "    # Apply PCA analysis\n",
    "    pca = PCA(n_components=1) # 3\n",
    "    pca_scores = pca.fit_transform(df_scaled)\n",
    "    eig_val = pca.explained_variance_ratio_ * 100\n",
    "    \n",
    "    # Prepare PCA result DataFrame, align with index\n",
    "    pca_scores = pd.DataFrame(pca_scores, index=df.index, columns=['PC1']) # , 'PC2', 'PC3'\n",
    "    pca_scores['PC1_Var'] = eig_val[0]\n",
    "    #pca_scores['PC2_Var'] = eig_val[1]\n",
    "    #pca_scores['PC3_Var'] = eig_val[2]\n",
    "\n",
    "    # Reset index to get back time information as column\n",
    "    pca_scores.reset_index(inplace=True)\n",
    "    \n",
    "    return pca_scores \n",
    "\n",
    "pca_results = {i: pca_analysis(pf_ts_wide[i]) for i in ID_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0293452-5a6e-44e5-968e-b180a224b3f5",
   "metadata": {},
   "source": [
    "We create a DataFrame consisting of the sample ID and the explained variance ratio of PC1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe74de3-3a70-4f22-9d42-f91fd46a0fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for site_id, df in pca_results.items():\n",
    "    var_value = df['PC1_Var'].iloc[0]  # 'PC1_Var' is the same for all rows within the DataFrame\n",
    "    rows.append({'ID': site_id, 'Dim.1_Var': var_value})\n",
    "\n",
    "# Convert the list of rows into a DataFrame\n",
    "pca_var_df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08715f54-96a1-4597-a17f-9c4847bb5c92",
   "metadata": {},
   "source": [
    "We can well investigate the explained variance per plankton group using boxplots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c16319-7e78-4696-8ff0-670000b8919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the explained variance by plankton group\n",
    "# Example IDs could be structured like 'ID_planktonic foraminifera', so split based on expected patterns\n",
    "pca_var_df['Group'] = pca_var_df['ID'].apply(lambda x: x.split('_')[1] if '_' in x else x)\n",
    "\n",
    "# Calculate the explained variance ranges for each plankton group\n",
    "explained_variance_grouped = pca_var_df.groupby('Group')['Dim.1_Var'].agg(['mean', 'min', 'max']).reset_index()\n",
    "\n",
    "# Boxplot of the explained variance per group\n",
    "import seaborn as sns\n",
    "plt.figure()\n",
    "sns.boxplot(x='Group', y='Dim.1_Var', data=pca_var_df)\n",
    "plt.title('Explained Variance Distribution per Plankton Group')\n",
    "plt.xlabel('Plankton Group')\n",
    "plt.ylabel('Explained Variance (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "explained_variance_grouped = pca_var_df.groupby('Group')['Dim.1_Var'].agg(['mean', 'min', 'max']).reset_index()\n",
    "print(explained_variance_grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e55734-a54d-4140-8d83-4d726c32ee3a",
   "metadata": {},
   "source": [
    "The first principal component (PC1) of each group explains a varying proportion of the variance, with planktonic foraminifera showing the highest (20%‚Äì65%) and coccolithophores showing the lowest (17%‚Äì31%).\n",
    "\n",
    "In addition, we aim to plot the explained variance on the map using the sample locations that are available in the dataset *core_list*. For that we first need to `merge` the two DataFrames *core_list* and *pca_var_df*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b199d1d2-af03-48d6-ab1c-48efade9e731",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_list_var = core_list.merge(pca_var_df, on='ID', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6828b4-95e3-4552-afd0-b3cf6ef877ee",
   "metadata": {},
   "source": [
    "Then we can turn the DataFrame into a geodataframe (check out the library `geopandas`) which we then plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68c6718-6df0-4a62-888a-11187e4878b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create geometry for GeoDataFrame using longitude and latitude\n",
    "geometry = [Point(xy) for xy in zip(core_list_var['lon'], core_list_var['lat'])]\n",
    "gdf = gpd.GeoDataFrame(core_list_var, geometry=geometry)\n",
    "\n",
    "# Plot with Cartopy\n",
    "fig, ax = plt.subplots(figsize=(4, 4), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "# Add map features\n",
    "ax.add_feature(cfeature.LAND, edgecolor='black', color='lightgrey')\n",
    "ax.add_feature(cfeature.OCEAN, color='white')\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "\n",
    "# Plot all data points on the map\n",
    "# Use Dim.1_Var to determine the size of the markers\n",
    "gdf.plot(ax=ax, marker='o', c=core_list_var['Dim.1_Var'], cmap='coolwarm', markersize=core_list_var['Dim.1_Var'] * 10,\n",
    "         alpha=0.7, transform=ccrs.PlateCarree(), legend=True)\n",
    "\n",
    "# Add a colorbar\n",
    "colorbar = plt.cm.ScalarMappable(cmap='coolwarm', norm=plt.Normalize(vmin=core_list_var['Dim.1_Var'].min(), vmax=core_list_var['Dim.1_Var'].max()))\n",
    "colorbar._A = []  # Dummy array for the colorbar\n",
    "cbar = fig.colorbar(colorbar, ax=ax, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "cbar.set_label('Explained variance from PC1')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eab39c-38eb-4f4f-9ef9-72c89e3cb005",
   "metadata": {},
   "source": [
    "## **Exercise 2: Time Series Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ebcfcd-e621-46df-b7ec-9e95401112da",
   "metadata": {},
   "source": [
    "The study examined how species groups evolve over time using PCA. PCA can sometimes reverse the direction of its components while preserving the underlying data patterns. To ensure all samples exhibit the same trend direction, a specific function is applied. This guarantees that trends ‚Äî whether increasing or decreasing over time ‚Äî remain consistent and are easier to compare across different samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73cbb37-b515-4afc-a3b2-f8d1b8137e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_pc1_trend(df, site_id):\n",
    "\n",
    "    df = df.copy()\n",
    "    \n",
    "    if len(df['Age_kaBP'].unique()) > 1:\n",
    "        \n",
    "        # Prepare the independent and dependent variables\n",
    "        X = df['Age_kaBP']\n",
    "        y = df['PC1']\n",
    "        \n",
    "        # Add a constant to the independent variable\n",
    "        X_const = sm.add_constant(X)  # This adds an intercept term\n",
    "        \n",
    "        # Fit the model\n",
    "        model = sm.OLS(y, X_const).fit()\n",
    "        \n",
    "        # Extract the slope\n",
    "        slope = model.params[1]  # params[1] gives the slope, params[0] gives the intercept\n",
    "    else:\n",
    "        slope = 0\n",
    "\n",
    "    # Set PC1_slope and adjust PC1 if necessary\n",
    "    df['PC1_slope'] = slope\n",
    "    if slope > 0:\n",
    "        print(f\"Adjusting slope for {site_id}: {slope}\")\n",
    "        df['PC1'] *= -1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcaaca5-1e4c-4a0a-8cb8-0528df16037b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adjusted_pca_results = {site_id: adjust_pc1_trend(pca_results[site_id], site_id) for site_id in ID_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbe8697-73d6-40d5-bb57-77674a6fa4a3",
   "metadata": {},
   "source": [
    "In the output of the previous code block we find the samples for which PC1 scores were adjusted to slope. We now want to verify the adjustment in the 'adjusted_pca_results' dictionary compared to the 'pca_results' dictionary. For this, we first select one sample printed in the output and extract it's values from the dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02716123-c6f8-42e0-8804-63b2a087e7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose ID\n",
    "ID = 'm35003-4_coccolithophore' # ! choose sample from the previously printed output\n",
    "\n",
    "# Extract the dataframe for the specified site ID\n",
    "df = pca_results[ID]\n",
    "df2 = adjusted_pca_results[ID]\n",
    "\n",
    "# Extract PC1 scores and Age_kaBP values\n",
    "y = df['PC1'].values\n",
    "y2 = df2['PC1'].values\n",
    "X = df['Age_kaBP'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd71a0e5-1ea4-43e7-9823-7132cb2817e0",
   "metadata": {},
   "source": [
    "**Exercise:** Plot the PC1 scores together with the linear regression line for the PC1 values of the sample together with the PC1 scores after the adjustment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfedc63-c401-4412-84f5-3db2665c1fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca0986ef-88f2-4072-a8e8-fbe27ddbc5a6",
   "metadata": {},
   "source": [
    "## 3. Data Availability and Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ad0121-3a4f-4e75-94d8-206c8164fc6d",
   "metadata": {},
   "source": [
    "The study used interpolation to create a consistent comparison of the first PC scores for planktonic foraminifera even though the individual time series have different time resolutions. They interpolated the first PC scores in 0.5 thousand-year (kyr) bins to better align the data for easier comparison of different samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c483ef1c-7f97-4354-8b36-885ede0f0a7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Combine all interpolated PC1 scores into a long format DataFrame\n",
    "adjusted_pca_results_long = pd.concat([df.assign(ID=id) for id, df in adjusted_pca_results.items()], ignore_index=True)\n",
    "\n",
    "# Create a binary availability indicator\n",
    "adjusted_pca_results_long['Availability'] = adjusted_pca_results_long['PC1'].notnull().astype(int) # Mark as 1 where PC1 data is available, else 0\n",
    "\n",
    "# Pivot the DataFrame\n",
    "heatmap_data = adjusted_pca_results_long.pivot_table(index='ID', columns='Age_kaBP', values='Availability', aggfunc='max')\n",
    "\n",
    "print(heatmap_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c4f533-d6ce-455a-b8fc-2efdaf8a3c5f",
   "metadata": {},
   "source": [
    "**Exercise:** Let's investigate the data availability for the different samples using a heatmap plot (`seaborn` library). We created a long format DataFrame out of the dictionary for this task and named it 'adjusted_pca_results_long' and pivoted the data afterwards. Investigate 'heatmap_data' and plot the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d2ca1b-faf8-4279-9beb-b7441390db12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc53ed7c-8028-4e46-b5d9-ccad6cdbb134",
   "metadata": {},
   "source": [
    "**Exercise:** Standardize age data across different samples by interpolating values to a common set of dates. First define a sequence of 0.5 thousand-year (kyr) bins from 0 to 24.5 kaBP using the `np.arange` function. Name it 'seq_interpol'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2139372-4461-4719-84e6-02cc5fd844b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc7559c-399b-4a2f-af38-5aad27170409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store interpolated results by ID\n",
    "pca_time_series = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cabcfd9-dcf3-4dbc-8714-e5d9131910bb",
   "metadata": {},
   "source": [
    "**Exercise:** Then 1) drop NaN values for the interpolation, 2) interpolate values using the `interp1d` function and 3) extract the dates from the sequence from the interpolated data. Apply these steps for each time series individually using a `for` loop. Because the time series/ DataFrames are stored in the dictionary, we need to call each time series as follows in the loop: `for site_id, df in adjusted_pca_results.items():` At the end of the loop, store the results (name: 'interpolated_values') to the 'pca_time_series' dictionary using `pca_time_series[site_id] = pd.DataFrame({'Age_kaBP': seq_interpol, 'PC1_score': interpolated_values})`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39525b7-9c9e-433e-9f65-fd746e96e45c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f48ee04e-6dd0-4eb1-9bb8-06601cf35196",
   "metadata": {},
   "source": [
    "**Exercise:** Print the new PC1 scores for a sample of your choice using `pca_time_series[i]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e9825e-e850-402e-b395-b584007d52a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71807da0-1cab-4475-99b7-2d8d19e8c5f2",
   "metadata": {},
   "source": [
    "**Exercise:** Repeat plotting the heatmap of data availability with the new dataset. First create pivoted data as before. Then plot the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea412dd-1878-4dfe-9b15-9ceabc1b4090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22ae775-5708-4b99-8a99-c8f53b7db54e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cc298b1-d89d-4078-a3a9-0812d8e7297b",
   "metadata": {},
   "source": [
    "## **Exercise 3: Time Series Prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cb0bac-fdd3-4d06-af15-42acff4c2448",
   "metadata": {},
   "source": [
    "## 4. Generalized Additive Model (GAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec18e88-506a-4e8d-b1a9-7e0b702eaf7e",
   "metadata": {},
   "source": [
    "Generalized Additive Models (GAMs) were used in the study to analyze the complex relationships between environmental factors (like temperature) and the response of planktonic foraminifera assemblages over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3882e371-3ba8-476b-aea7-ee8d4868c1c2",
   "metadata": {},
   "source": [
    "## 4.1 Select Data for Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0516801-1181-44c2-8584-5d4ff70f7747",
   "metadata": {},
   "source": [
    "To avoid edge effects, the study focused on time periods that all the samples covered. This approach helped ensure that the comparisons of biodiversity changes over time are not influenced by differences in data collection. Subsets were created for planktonic foraminifera, dinocysts, and coccolithophores based on their IDs, facilitating focused analyses on each group's responses to climate change. In the end, the following codeblock provides 1. variables for fitting the GAM models and 2. Sets of ages over which we will predict trends in the planktonic community data using the fitted GAMs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2958243-3846-4a43-a311-45a493f6ce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all interpolated PC1 scores into a long format DataFrame\n",
    "interpolation_long = pd.concat([df.assign(ID=id) for id, df in pca_time_series.items()], ignore_index=True)\n",
    "\n",
    "# Create subsets for each plankton group based on the ID column\n",
    "interpolation_long_PF = interpolation_long[interpolation_long['ID'].str.contains('_planktonic foraminifera')]\n",
    "interpolation_long_dino = interpolation_long[interpolation_long['ID'].str.contains('_dinocyst')]\n",
    "interpolation_long_cocco = interpolation_long[interpolation_long['ID'].str.contains('_coccolithophore')]\n",
    "\n",
    "# Adjust the data to set Age_kaBP to NaN where PC1_score is NaN\n",
    "def adjust_for_nan(df):\n",
    "    df.loc[df['PC1_score'].isna(), 'Age_kaBP'] = np.nan\n",
    "    return df\n",
    "\n",
    "# Group DataFrames\n",
    "interpolation_long_PF = adjust_for_nan(interpolation_long_PF)\n",
    "interpolation_long_dino = adjust_for_nan(interpolation_long_dino)\n",
    "interpolation_long_cocco = adjust_for_nan(interpolation_long_cocco)\n",
    "\n",
    "# Determine the Common Age Range\n",
    "def get_common_age_range(interpolation_long_group):\n",
    "    # Extract the minimum and maximum ages across all time series\n",
    "    min_age = interpolation_long_group.groupby('ID')['Age_kaBP'].min().max()\n",
    "    max_age = interpolation_long_group.groupby('ID')['Age_kaBP'].max().min()\n",
    "    return min_age, max_age\n",
    "\n",
    "# Group Common Age Range \n",
    "pf_min_age, pf_max_age = get_common_age_range(interpolation_long_PF)\n",
    "cocco_min_age, cocco_max_age = get_common_age_range(interpolation_long_cocco)\n",
    "dino_min_age, dino_max_age = get_common_age_range(interpolation_long_dino) \n",
    "\n",
    "# Data used for fitting GAM and model predictions:\n",
    "\n",
    "# 1. Independent variable (predictor) and dependent variable (target) without any NaN values\n",
    "# (e.g. age_kabp_valid_PF is the valid predictor and pc1_score_valid_PF is the valid target for planktonic foraminifera)\n",
    "age_kabp_PF = interpolation_long_PF['Age_kaBP']\n",
    "pc1_score_PF = interpolation_long_PF['PC1_score']\n",
    "valid_indices_PF = ~np.isnan(age_kabp_PF) & ~np.isnan(pc1_score_PF)\n",
    "age_kabp_valid_PF = age_kabp_PF[valid_indices_PF]\n",
    "pc1_score_valid_PF = pc1_score_PF[valid_indices_PF]\n",
    "age_kabp_dino = interpolation_long_dino['Age_kaBP']\n",
    "pc1_score_dino = interpolation_long_dino['PC1_score']\n",
    "valid_indices_dino = ~np.isnan(age_kabp_dino) & ~np.isnan(pc1_score_dino)\n",
    "age_kabp_valid_dino = age_kabp_dino[valid_indices_dino]\n",
    "pc1_score_valid_dino = pc1_score_dino[valid_indices_dino]\n",
    "age_kabp_cocco = interpolation_long_cocco['Age_kaBP']\n",
    "pc1_score_cocco = interpolation_long_cocco['PC1_score']\n",
    "valid_indices_cocco = ~np.isnan(age_kabp_cocco) & ~np.isnan(pc1_score_cocco)\n",
    "age_kabp_valid_cocco = age_kabp_cocco[valid_indices_cocco]\n",
    "pc1_score_valid_cocco = pc1_score_cocco[valid_indices_cocco]\n",
    "\n",
    "# 2. Sets of ages (predictor) over which we will predict trends in the planktonic community data using the fitted GAMs\n",
    "N = 2000 # Number of points to evaluate the smooth\n",
    "Age_range_PF = np.linspace(pf_min_age, pf_max_age, N)\n",
    "Age_range_cocco = np.linspace(cocco_min_age, cocco_max_age, N)\n",
    "Age_range_dino = np.linspace(dino_min_age, dino_max_age, N)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf6174d-eb51-479a-ae9f-1bb4a5ef3f39",
   "metadata": {},
   "source": [
    "## 4.2 Fit GAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bb6b50-96a1-4d77-ba01-496b92648ee6",
   "metadata": {},
   "source": [
    "**Exercise:** Fit a Generalized Additive Model (GAM) for each plankton group by creating 15 basis splines from their respective valid age ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54505384-ea86-4d13-b160-66d72edd5d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83c49ba4-375b-4fc1-a8af-c9c0fbbcaf02",
   "metadata": {},
   "source": [
    "## 4.3 Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46c87d1-20fd-4836-b360-351f9a86aa17",
   "metadata": {},
   "source": [
    "**Exercise:** Now create spline basis functions from predefined age ranges for the prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0c28d1-8aa6-4936-8214-95bee8c594ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9554664-02d7-4b91-9c86-a9a6833ed385",
   "metadata": {},
   "source": [
    "The fitted GAMs can now be used to generate predictions for the defined age ranges based on the newly defined spline basis functions. This step quantifies the expected responses over the defined age ranges, providing insights into the relationships between age and PC1 scores for each group. We account for uncertainty by calculating the confidence intervals alongside the predicted values. We store the results in DataFrames that include the fitted values and their corresponding lower and upper confidence bounds for further analysis in plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd338ad0-a984-4ac1-bdb2-f0988215a8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions and confidence intervals for planktonic foraminifera\n",
    "preds_PF = mod_PF.get_prediction(bsplines_PF).summary_frame(alpha=0.05)\n",
    "\n",
    "# Generate predictions and confidence intervals for coccolithophores\n",
    "preds_cocco = mod_cocco.get_prediction(bsplines_cocco).summary_frame(alpha=0.05)\n",
    "\n",
    "# Generate predictions and confidence intervals for dinocysts\n",
    "preds_dino = mod_dino.get_prediction(bsplines_dino).summary_frame(alpha=0.05)\n",
    "\n",
    "GAM_PF = pd.DataFrame({\n",
    "   \"Age_kaBP\": Age_range_PF,  # Match the length of predictions\n",
    "   \"fit\": preds_PF[\"mean\"],\n",
    "   \"lower\": preds_PF[\"mean_ci_lower\"],\n",
    "   \"upper\": preds_PF[\"mean_ci_upper\"]\n",
    "})\n",
    "\n",
    "# Create a DataFrame with the predictions and confidence intervals\n",
    "GAM_cocco = pd.DataFrame({\n",
    "    \"Age_kaBP\": Age_range_cocco,  # Use Age_range_cocco directly\n",
    "    \"fit\": preds_cocco[\"mean\"],\n",
    "    \"lower\": preds_cocco[\"mean_ci_lower\"],\n",
    "    \"upper\": preds_cocco[\"mean_ci_upper\"]\n",
    "})\n",
    "\n",
    "# Create a DataFrame with the predictions and confidence intervals\n",
    "GAM_dino = pd.DataFrame({\n",
    "    \"Age_kaBP\": Age_range_dino,  # Use Age_range_dino directly\n",
    "    \"fit\": preds_dino[\"mean\"],\n",
    "    \"lower\": preds_dino[\"mean_ci_lower\"],\n",
    "    \"upper\": preds_dino[\"mean_ci_upper\"]\n",
    "})\n",
    "\n",
    "results = {\n",
    "    'dinocyst': {'data': interpolation_long_dino, 'gam': GAM_dino, 'color': '#CD950C', 'label': 'Dinocysts', 'min_age': dino_min_age, 'max_age': dino_max_age},\n",
    "    'coccolithophore': {'data': interpolation_long_cocco, 'gam': GAM_cocco, 'color': '#36648B', 'label': 'Coccolithophores', 'min_age': cocco_min_age, 'max_age': cocco_max_age},\n",
    "    'planktonic foraminifera': {'data': interpolation_long_PF, 'gam': GAM_PF, 'color': '#9D9E9E', 'label': 'Planktonic Foraminifera', 'min_age': pf_min_age, 'max_age': pf_max_age}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05a10c6-a236-43fb-b699-2db36d2be4b9",
   "metadata": {},
   "source": [
    "## 4.4 Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca0c07a-bd6c-4ba8-a43d-d74633a75fa6",
   "metadata": {},
   "source": [
    "Spline basis functions are a way to help create smooth curves or lines to represent data in a flexible manner. In this study, the smoothed GAM functions were plotted to examine trends in plankton communities in relation to temperature anomalies. \n",
    "\n",
    "Figure 1 demonstrates that all three plankton groups exhibit a consistent and unidirectional trend in their compositional changes over the past 24,000 years. Notably, since the explained variance by the first principal component (PC1) is highest for planktonic foraminifera, this group has historically shown more pronounced shifts in composition compared to dinocysts and coccolithophores. The authors conclude that planktonic foraminifera may be more sensitive to environmental changes, potentially reflecting their ecological responses to past climate fluctuations.\n",
    "\n",
    "Figure 2 confirms that the changes in plankton assemblages coincide with the onset of global warming approximately 15,500 to 17,000 years ago. The continuous changes in community composition observed in planktonic foraminifera and dinocysts continued throughout the Holocene, whereas coccolithophores exhibited a constant rate of change regardless of temperatures. According to the study, this highlights that while some groups adapt quickly to changing climates, others like coccolithophores might be influenced by different ecological interactions or drivers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889f1496-e2d6-429c-9d5f-7a52f8edd5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1\n",
    "\n",
    "for group_name, group_data in results.items():\n",
    "    fig, ax = plt.subplots(figsize=(6.4, 2.8))\n",
    "\n",
    "    # Plot interpolated PC1 scores\n",
    "    for id_, group in group_data['data'].groupby('ID'):\n",
    "        ax.plot(group['Age_kaBP'], group['PC1_score'], color='grey', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "    # Plot the GAM fit\n",
    "    ax.plot(group_data['gam']['Age_kaBP'], group_data['gam']['fit'], color=group_data['color'], linewidth=2, label=group_data['label'])\n",
    "\n",
    "    # Plot the 95% confidence interval\n",
    "    ax.fill_between(group_data['gam']['Age_kaBP'], group_data['gam']['lower'], group_data['gam']['upper'], color=group_data['color'], alpha=0.3)\n",
    "\n",
    "    # Set axis labels and title\n",
    "    ax.set_xlabel('Age (ka)')\n",
    "    ax.set_ylabel('PC1 Score')\n",
    "    ax.set_title(f'GAM Fit for {group_data[\"label\"]}')\n",
    "\n",
    "    # Enforce limits after plotting\n",
    "    ax.set_xlim(2, 24)  # Set limits based on the common age range\n",
    "    ax.set_ylim(-5.5, 7)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(6.4, 5), sharex=True, gridspec_kw={'height_ratios': [3, 1]})\n",
    "\n",
    "# Figure 2\n",
    "\n",
    "# Plot the GAM fit and confidence intervals for each species group\n",
    "for group_name, group_data in results.items():\n",
    "    ax1.plot(group_data['gam']['Age_kaBP'], group_data['gam']['fit'], color=group_data['color'], label=group_data['label'])\n",
    "    ax1.fill_between(group_data['gam']['Age_kaBP'], group_data['gam']['lower'], group_data['gam']['upper'], color=group_data['color'], alpha=0.3)\n",
    "\n",
    "# Customize the upper plot (GAM functions)\n",
    "ax1.set_ylabel('PC1 Score')\n",
    "ax1.set_xlim(0, 24)\n",
    "ax1.legend(loc='upper right')\n",
    "\n",
    "# Plot the temperature anomaly on the lower subplot\n",
    "ax2.plot(GMST['Age_kaBP'], GMST['GMST'], color='red', linewidth=1)\n",
    "ax2.set_xlabel('Age (ka)')\n",
    "ax2.set_ylabel('Temperature Anomaly (¬∞C)')\n",
    "ax2.set_xlim(0, 24)\n",
    "\n",
    "# Fine-tuning the layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f04479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
