{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e6cafd1-08e5-478f-b0ba-e78c0f973298",
   "metadata": {},
   "source": [
    "<img src=\"../Images/DSC_Logo.png\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d573c7-36c8-4bd2-91b6-f7bdb10cbe3a",
   "metadata": {},
   "source": [
    "# Time Series Theory in Python - Part 2: Stationary Time Series Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48e257c-a346-450f-8147-329f0844eff2",
   "metadata": {},
   "source": [
    "This notebook provides an overview of stationary time series models, with a specific emphasis on the autoregressive moving average (ARMA) process. ARMA models facilitate intuitive interpretations of how past values and past errors influence current observations, which can inform decision-making processes. Additionally, the ARMA model serves as the foundation for more complex models, including ARIMA (which incorporates differencing for non-stationary data) and seasonal or multivariate variants such as SARIMA and VARMA. While ARMA models offer valuable tools for understanding time series behavior, it is important to recognize their limitations when dealing with complex real-world data, which may require alternative modeling approaches that account for non-linear behavior or non-stationary processes.\n",
    "\n",
    "The notebook also outlines the general steps involved in the development of time series models. These steps include identifying an appropriate model type, estimating model parameters, fitting the selected model, testing the residuals to ensure model adequacy, and generating forecasts based on the fitted model. Notably, these methodologies are not limited to stationary models; they are also applicable to non-stationary or non-linear time series, providing a general framework for time series analysis and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e345e3b-efe2-4991-835d-c879d1ecd7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from pandas.plotting import lag_plot\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from statsmodels.tsa.arima_process import arma_generate_sample\n",
    "from statsmodels.tsa.arima.model import ARIMA \n",
    "from statsmodels.tsa.stattools import kpss\n",
    "from scipy import stats \n",
    "\n",
    "from PythonTsa.datadir import getdtapath\n",
    "dtapath=getdtapath()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104c2ee5-f3e2-4725-86f3-5f9f7731fedf",
   "metadata": {},
   "source": [
    "## 1. Moving Average (MA) Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbd41ba-1504-41b0-ad55-b3befc7f0e82",
   "metadata": {},
   "source": [
    "Generating MA(2) Model given by the equation:\n",
    "<span style=\"font-size: 24px;\">$$ X_t = \\varepsilon_t + 0.6 \\varepsilon_{t-1} - 0.3 \\varepsilon_{t-2} $$</span>\n",
    "where  <span style=\"font-size: 18px;\">$ \\varepsilon_t \\sim \\text{iid} \\, N(0, 1). $</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90ceb28-ad58-4b41-b1dd-577f64923f75",
   "metadata": {},
   "source": [
    "With the Python function `arma_generate_sample`, we can get samples from an autoregressive moving average (ARMA) process defined by specified parameters.\n",
    "\n",
    "\n",
    "The time series displays neither trend nor seasonality and appears stationary. The significant ACF values at lags 1 and 2, along with the patterns observed in the PACF and lag plots, confirm that the time series follows the MA(2) process. The MA(2) model expresses the current value of the time series as a function of the current and previous two noise terms. The lag plot for lag 1 shows a positive relationship, while the lag plot for lag 2 suggests a weaker or negative correlation. Furthermore, the absence of discernible patterns in the lag plots for lags 3 and 4 reinforces that these lags do not significantly contribute to the current value, aligning with the typical behavior of an MA(2) process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677a031c-71a0-4847-9ffd-0d9649d59d8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the MA parameters\n",
    "ma = np.array([1, 0.6, -0.3])  # MA coefficients\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(123457)\n",
    "\n",
    "# Generate a sample from the ARMA process\n",
    "x = arma_generate_sample(ar=[1], ma=ma, nsample=500)  # AR part is set to [1] for no AR component; sample of size (length) 500\n",
    "\n",
    "# Check the type of x (should be a numpy array)\n",
    "print(type(x))  # Output: <class 'numpy.ndarray'>\n",
    "\n",
    "# Convert x to a pandas Series\n",
    "x = pd.Series(x)\n",
    "\n",
    "# Check the type of x again (now it should be a Series)\n",
    "print(type(x))  # Output: <class 'pandas.core.series.Series'>\n",
    "\n",
    "# Plot the time series\n",
    "x.plot()\n",
    "plt.title('Generated MA(2) Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.show()\n",
    "\n",
    "# Plot ACF and PACF\n",
    "plot_acf(x, lags=20)\n",
    "plt.title('ACF of the Generated MA(2) Series') # we see: MA(2) is at lag 1 & 2 out of the band\n",
    "plt.show()\n",
    "plot_pacf(x, lags=20)\n",
    "plt.title('PACF of the Generated MA(2) Series')\n",
    "plt.show()\n",
    "\n",
    "# Lag plots for lag 1 and 2\n",
    "fig = plt.figure()\n",
    "lag_plot(x, lag=1, ax=fig.add_subplot(211))\n",
    "plt.title('Lag Plot (Lag 1)')\n",
    "lag_plot(x, lag=2, ax=fig.add_subplot(212))\n",
    "plt.title('Lag Plot (Lag 2)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Lag plots for lags 3 and 4\n",
    "fig = plt.figure()\n",
    "lag_plot(x, lag=3, ax=fig.add_subplot(211))\n",
    "plt.title('Lag Plot (Lag 3)')\n",
    "lag_plot(x, lag=4, ax=fig.add_subplot(212))\n",
    "plt.title('Lag Plot (Lag 4)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11522c4a-6fe2-48c8-99b6-d1e4362bf0bf",
   "metadata": {},
   "source": [
    "## 2. Autoregressive Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddecd01-f9d2-4c88-b88c-2fe49fd4bbdc",
   "metadata": {},
   "source": [
    "Generating AR(2) Model given by the equation:  \n",
    "<span style=\"font-size: 24px;\">$$ X_t = 0.8 X_{t-1} - 0.3 X_{t-2} + \\varepsilon_t $$</span>  \n",
    "\n",
    "where  <span style=\"font-size: 18px;\">$ \\varepsilon_t \\sim \\text{iid} \\, N(0, 1). $</span>\n",
    "\n",
    "The time series shows no trend or seasonality and appears stationary. The PACF values are almost zero after lag 3, indicating that the series follows an autoregressive process, where the current observation is primarily influenced by the most recent values (two most recent values for AR(2)). The ACF shows tailing off, which is also characteristic of autoregressive processes. However, significant positive autocorrelation at lag 11 suggests that there may be more complexity in the data needing further investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba4ab8-5998-4383-8a61-1d4cf5f0fa81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the AR parameters (AR(2) model)\n",
    "ar = np.array([1, -0.8, 0.3])  # AR coefficients\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(123457)\n",
    "\n",
    "# Generate a sample from the AR process\n",
    "x = arma_generate_sample(ar=ar, ma=[1], nsample=500)  # ma=[1] means no MA part in the model; sample of size (length) 500\n",
    "\n",
    "# Convert the generated sample to a pandas Series\n",
    "x = pd.Series(x)\n",
    "\n",
    "# Plot the time series\n",
    "x.plot()\n",
    "plt.title('Generated AR(2) Sample')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.show()\n",
    "\n",
    "# Plot ACF and PACF\n",
    "plot_acf(x, lags=20)\n",
    "plt.title('ACF of the Generated AR(2) Sample')\n",
    "plt.show()\n",
    "plot_pacf(x, lags=20)\n",
    "plt.title('PACF of the Generated AR(2) Sample')\n",
    "plt.show()\n",
    "\n",
    "# Lag plot for lag 11\n",
    "lag_plot(x, lag=11)\n",
    "plt.title('Lag Plot (Lag 11)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25c924d-807f-4271-8daf-21618ee04de1",
   "metadata": {},
   "source": [
    "## 3. Autoregressive Moving Average (ARMA) Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e97aa7-437d-498a-b37f-bb2e61e11695",
   "metadata": {},
   "source": [
    "Consider the following ARMA(2,2) model:\n",
    "\n",
    "<span style=\"font-size: 18px;\">$$\n",
    "X_t = 0.8 X_{t-1} - 0.6 X_{t-2} + \\varepsilon_t + 0.7 \\varepsilon_{t-1} + 0.4 \\varepsilon_{t-2}\n",
    "$$</span>\n",
    "\n",
    "In an ARMA model, which combines both AR and MA components, the current value $X_t$ is expressed as a linear combination of its previous values **and** past error terms ($\\varepsilon $). Specifically, an ARMA(p,q) model combines the features of AR(p), which captures the influence of the past values, and MA(q), which incorporates the effects of past error terms.\n",
    "\n",
    "The generated time series is stationary and exhibits a rapid decay to zero for both the ACF and PACF. However, many ACF and PACF values remain nonzero for lags equal to or greater than 3, indicating a tailing off behavior typical of an ARMA(2,2) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a32d4aa-34fe-4074-bd9d-11be3a6fff88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(12357)\n",
    "\n",
    "# Define AR and MA parameters for the ARMA model\n",
    "ar = np.array([1, -0.8, 0.6])  # AR coefficients\n",
    "ma = np.array([1, 0.7, 0.4])   # MA coefficients\n",
    "\n",
    "# Create an ARMA process\n",
    "arma_process = sm.tsa.ArmaProcess(ar, ma)\n",
    "\n",
    "# Check for stationarity and invertibility\n",
    "print(\"Stationarity:\", arma_process.isstationary)  # Check if the process is stationary\n",
    "print(\"Invertibility:\", arma_process.isinvertible)  # Check if the process is invertible\n",
    "\n",
    "# Generate a sample from the ARMA process\n",
    "y = arma_generate_sample(ar=ar, ma=ma, nsample=500)\n",
    "y = pd.Series(y, name='y')  # Convert the generated data to a pandas Series\n",
    "\n",
    "# Plot the time series\n",
    "plt.figure()\n",
    "y.plot(title='ARMA(2, 2) Time Series', xlabel='Time', ylabel='Value')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot ACF and PACF\n",
    "plot_acf(y, lags=20)\n",
    "plt.show()\n",
    "plot_pacf(y, lags=20)\n",
    "plt.show()\n",
    "\n",
    "# Lag plot for lag 11\n",
    "lag_plot(y, lag=11)\n",
    "plt.title('Lag Plot (Lag 11)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036a18fd-3c21-4be5-bd02-5524de7396cb",
   "metadata": {},
   "source": [
    "### Choose model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75671aa8-5ed7-4f8c-840a-be00ba9fbdc9",
   "metadata": {},
   "source": [
    "We will now assume that we no longer remember the source of the sample and aim to construct an ARMA(p,q) model for it. The challenge lies in determining the appropriate orders (p,q). To address this, we model various combinations of orders p and q and compare them using the metrics AIC, BIC, and HQIC. AIC (Akaike Information Criterion), BIC (Bayesian Information Criterion), and HQIC (Hannan-Quinn Information Criterion) are statistical criteria used to compare the goodness of fit of multiple models while penalizing for model complexity, helping to avoid overfitting. A smaller value indicates a better model fit relative to the complexity of the model. \n",
    "\n",
    "The decreasing AIC values suggest that the models are improving as we increase the complexity (i.e., higher values of q and/or p), which is expected in time series modeling. BIC and HQIC suggest (2,2), while AIC suggests a higher-order model. \n",
    "\n",
    "Note: \n",
    "\n",
    "- ARMA modeling using the `statsmodels` library is performed with the Python function ARIMA, where the differencing parameter is set to zero (i.e., order=(p,0,q)). This fits an ARMA(p,q) model to the data.\n",
    "\n",
    "- Warnings serve as a signal that model assumptions, the fitting process, and possibly the data itself require review. It helps to ensure that the models chosen are appropriate and that the estimates produced are reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1678e3dc-3e0c-4ebb-b1ba-f145eb37d7f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_p = 6 # how many past values of the series are used to predict future values\n",
    "max_q = 7 # number of lagged forecast errors in the prediction equation\n",
    "model_metrics = []\n",
    "\n",
    "print(\"Fitting ARMA models...\")\n",
    "\n",
    "for p in range(max_p + 1):\n",
    "    for q in range(max_q + 1):\n",
    "        if p == 0 and q == 0:\n",
    "            continue  # Skip the case where both p and q are zero\n",
    "        \n",
    "        try:\n",
    "            model = ARIMA(y, order=(p, 0, q)).fit()  # Use ARIMA with d=0 for ARMA\n",
    "            model_metrics.append((p, q, model.aic, model.bic, model.hqic))  # Store p, q, metrics\n",
    "            print(f\"Fitted ARIMA({p}, 0, {q}) with AIC: {model.aic}, BIC: {model.bic}, HQIC: {model.hqic}\")  # Print metrics for each fitted model\n",
    "        except Exception as e:\n",
    "            print(f\"Error fitting ARIMA({p}, 0, {q}): {e}\")\n",
    "\n",
    "# Convert model metrics to DataFrame for easier analysis\n",
    "metrics_df = pd.DataFrame(model_metrics, columns=['p', 'q', 'AIC', 'BIC', 'HQIC'])\n",
    "\n",
    "# Print model metrics\n",
    "print(\"\\nModel Metrics for Different ARMA Models:\")\n",
    "print(metrics_df)\n",
    "\n",
    "# Get the best model based on the minimum AIC\n",
    "if not metrics_df.empty:\n",
    "    best_model = metrics_df.loc[metrics_df['AIC'].idxmin()] # choose best model based on AIC only\n",
    "    print(\"\\nBest ARMA Model (p, q, AIC):\", best_model)\n",
    "else:\n",
    "    print(\"No models were fitted successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d969faaf-a6e8-45b3-81f4-20b4d5bdd1ed",
   "metadata": {},
   "source": [
    "The function `sm.tsa.arma_order_select_ic()` is a built-in model selection tool in the `statsmodels` library that automates the process of determining the best ARMA model orders based on specified criteria (AIC, BIC, HQIC):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5020e9-9e3c-4ff4-93b3-86010de605a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inf = sm.tsa.arma_order_select_ic(y, max_ar=6, max_ma=7, ic=['aic', 'bic', 'hqic'], trend='c') # for statsmodels 0.13.0 and later, trend=’n’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a09067d-70e8-4136-9d41-3a208f7ead2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best AR term (p for minimum AIC):\", inf.aic_min_order[0])\n",
    "print(\"Best MA term (q for minimum AIC):\", inf.aic_min_order[1])\n",
    "\n",
    "print(\"Best AR term (p for minimum BIC):\", inf.bic_min_order[0])\n",
    "print(\"Best MA term (q for minimum BIC):\", inf.bic_min_order[1])\n",
    "\n",
    "print(\"Best AR term (p for minimum HQIC):\", inf.hqic_min_order[0])\n",
    "print(\"Best MA term (q for minimum HQIC):\", inf.hqic_min_order[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43c5290-8975-406b-9385-17ca832256eb",
   "metadata": {},
   "source": [
    "### Fit model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbe41a0-e7c3-457b-939f-9901736b7651",
   "metadata": {},
   "source": [
    "Based on the results from the model testing process and the understanding that the sample originates from an ARMA(2, 2) model, we proceed to fit this model to the data, analyze the fitted model and the residuals. \n",
    "\n",
    "The summary statistics reveal key characteristics of the fitted model, including the estimated coefficients, standard errors, and the goodness-of-fit measures. Analyzing the residuals is crucial for diagnosing how well the chosen model fits the data and testing for white noise residuals. If the residuals exhibit significant autocorrelation in the ACF/PACF plots or show significant deviations from normality, it may indicate that the model is not properly specified or suitable for the data.\n",
    "\n",
    "The model appears to fit the data well. The residuals from the model exhibit no significant autocorrelation or evidence of non-normality (hence, behave like those of white noise), suggesting that the model is appropriately specified for the time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbc7109-daf5-42e2-a746-7f244c1deab9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the ARMA(2,2) model\n",
    "arma22 = ARIMA(y, order=(2,0,2), trend='n').fit()\n",
    "print(arma22.summary())\n",
    "\n",
    "# Analyze the residuals\n",
    "resid22 = arma22.resid\n",
    "\n",
    "# Plot ACF and PACF of the residuals\n",
    "plot_acf(resid22, lags=20)\n",
    "plt.show()\n",
    "plot_pacf(resid22, lags=20)\n",
    "plt.show()\n",
    "\n",
    "# Perform the Ljung-Box test for residuals\n",
    "    # Calculate Ljung-Box test statistics and p-values\n",
    "ljung_box_results = acorr_ljungbox(resid22, lags=25, return_df=True)\n",
    "    # Create a plot for the p-values\n",
    "plt.figure()\n",
    "plt.plot(ljung_box_results['lb_pvalue'], marker='o', linestyle='-', color='b')\n",
    "plt.axhline(y=0.05, color='r', linestyle='--')  # 5% significance level\n",
    "plt.title('Ljung-Box Test P-Values')\n",
    "plt.xlabel('Lags')\n",
    "plt.ylabel('P-Value')\n",
    "plt.xticks(np.arange(0, 26, 1))\n",
    "plt.xticks(ljung_box_results.index)  # Set x-ticks to all lags\n",
    "plt.gca().set_xticklabels([str(int(x)) if x % 2 == 0 else '' for x in ljung_box_results.index])\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Q-Q plot\n",
    "plt.figure()\n",
    "sm.qqplot(resid22, line='q', ax=plt.gca())\n",
    "plt.title('Q-Q Plot (Sample vs Theoretical Quantiles)')\n",
    "plt.grid()\n",
    "\n",
    "# Perform the normality test on residuals\n",
    "normaltest_result = stats.normaltest(resid22)\n",
    "print(\"Normality test result:\", normaltest_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386fc6e7-5177-4762-a649-1719acae1f69",
   "metadata": {},
   "source": [
    "### Predict model:\n",
    "\n",
    "For the specified time range, both the initial part of the out-of-sample forecasts and the in-sample predictions appear satisfactory. It is a common occurrence in ARIMA time series forecasting for predictions made further into the future to converge toward a constant value, typically the mean of the historical data. Additionally, the increasing uncertainty of predictions is evident in the wider confidence intervals for more distant out-of-sample forecasts compared to those for in-sample predictions or closer out-of-sample predictions, as the model has less information when forecasting beyond the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b38792-3959-4b0f-b025-6e98519e6ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for a specified range (start=450, end=520)\n",
    "pred = arma22.get_prediction(start=450, end=520)\n",
    "predicts = pred.predicted_mean\n",
    "predconf = pred.conf_int()\n",
    "\n",
    "# Combine observed data, predictions, and confidence intervals into a DataFrame\n",
    "predframe = pd.concat([y[450:], predicts, predconf], axis=1)\n",
    "predframe.columns = ['Observed', 'Predicted', 'Lower CI', 'Upper CI']\n",
    "\n",
    "# Plot observed, predicted, and confidence intervals\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(predframe['Observed'], label='Observed', color='blue')\n",
    "plt.plot(predframe['Predicted'], label='Predicted', color='red')\n",
    "plt.fill_between(predframe.index, predframe['Lower CI'], predframe['Upper CI'], color='gray', alpha=0.5, label='Confidence Interval')\n",
    "plt.title('ARMA(2, 2) Predictions and Confidence Intervals')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da9b690",
   "metadata": {},
   "source": [
    "Forecasts are not so good although the resulting model fits well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ec8eb6-9a55-4368-bd53-09c2a7f81b8b",
   "metadata": {},
   "source": [
    "### **Example 1: The NAO Index Since January 1950**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b4c695-2e08-400f-abe8-7bfd362db971",
   "metadata": {},
   "source": [
    "The time series is the monthly mean North Atlantic Oscillation (NAO) index since January 1950. The series appears stationary (compare notebook C1). We will treat the NAO series as originating from an ARMA process and aim to build an ARMA(p,q) model. Both AR and MA components could be viable options; however, the evident cutoff in the PACF plot after lag 1 suggests that an autoregressive process may be more appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e74684-b7e6-4e1f-90ba-e3eac82d71b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the NAO dataset\n",
    "nao = pd.read_csv(dtapath + 'nao.csv', header=0)\n",
    "\n",
    "# Create a time index\n",
    "timeindex = pd.date_range('1950-01', periods=len(nao), freq='ME')\n",
    "nao.index = timeindex\n",
    "\n",
    "# Extract NAO index as a Series\n",
    "naots = nao['index']  # Ensure 'index' corresponds to the correct column name\n",
    "\n",
    "# Plot the NAO index time series\n",
    "naots.plot(title='NAO Index Time Series', xlabel='Date', ylabel='NAO Index')\n",
    "plt.show()\n",
    "\n",
    "# Plot ACF\n",
    "fig = plt.figure()\n",
    "plot_acf(naots, lags=50)\n",
    "plt.title(\"ACF of the Time Series\")\n",
    "plt.show()\n",
    "\n",
    "# Plot PACF\n",
    "fig = plt.figure()\n",
    "plot_pacf(naots, lags=50)\n",
    "plt.title(\"PACF of the Time Series\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Lag Plot\n",
    "lag_plot(naots)\n",
    "plt.title('Lag Plot of the Time Series')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5252f24c-7e77-44f6-a0e5-b66a3493a2f0",
   "metadata": {},
   "source": [
    "**Exercise:** Fit and evaluate suitable models for the time series and select the best model based on AIC, BIC, and HQIC criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dbd7eb-b323-43f5-b4c7-1a6944d8dada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d7d3fd-82d8-4591-bb76-f0fd9a5fb4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b05f2e1-a8f0-4f4d-b143-5e829981356e",
   "metadata": {},
   "source": [
    "**Exercise:** Fit the best model. What is the value of the AR coefficient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44ce2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdf26fae-064f-4682-b96a-cf5e992b6098",
   "metadata": {},
   "source": [
    "**Exercise:** Analyze the residuals from the fitted ARIMA model to assess whether the model fits well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feb9271-661e-4a98-9601-b84f977b76a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7599a5bc-74ad-4970-ac0b-4478f7148cfd",
   "metadata": {},
   "source": [
    "**Exercise:** Use the fitted model for out-of-sample and in-sample predictions from April 2010 to December 2019. Plot the predictions and confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afd5ac5-3a55-4410-96d4-1a6b3711cb2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a60c9daf-ab14-4b19-9810-4122a98f840a",
   "metadata": {},
   "source": [
    "## 4. Stationarity Test and Differencing\n",
    "\n",
    "One limitation of ARMA models is the stationarity condition. In many real-world time series, data can be thought of as being composed of two components: a non-stationary trend component and a zero-mean stationary component. Several strategies exist to achieve stationarity in a non-stationary time series, including differencing, detrending/decompostion and smoothing (see also notebook C3). Here, we demonstrate the differencing technique to stationarize time series. Statistical tests like the KPSS (Kwiatkowski-Phillips-Schmidt-Shin) test can be employed to assess the stationarity of a time series. In the `statsmodels.tsa.stattools` module, the function `kpss` performs the KPSS stationarity test, where the argument `regression='c'` indicates that the test is assessing the stationarity of a time series without a clear trend or obvious seasonality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44676fe-f9aa-43da-a854-a61c970b7f5b",
   "metadata": {},
   "source": [
    "### **Example 2: Global Annual Mean Surface Air Temperature Changes Series (1880-1985)**\n",
    "\n",
    "The time series dataset contains global mean surface air temperature changes from 1880 to 1985, as reported by Hansen and Lebedeff (1987). The temperature changes indicated in the study are relative to the average global mean surface air temperature derived from the baseline period of 1951-1980. The frequency of the time series is annual, meaning that seasonal variations in the annual cycle are not included. The trend in the time series illustrates the global warming. We apply the first difference to the time series to remove the trend and make it stationary (tested with KPSS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e239b1f9-364c-4e7a-912e-94dcaf343518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "tep = pd.read_csv(dtapath + 'Global mean surface air temp changes 1880-1985.csv', header=None)\n",
    "\n",
    "# Create a date index\n",
    "dates = pd.date_range('1880-12', periods=len(tep), freq='A-DEC')\n",
    "tep.index = dates\n",
    "tepts = pd.Series(tep[0], name='tep')\n",
    "\n",
    "# Plot the original time series\n",
    "plt.plot(tepts, color='b')\n",
    "plt.title('Global Mean Surface Air Temperature Changes (1880-1985)')\n",
    "plt.show()\n",
    "\n",
    "# Differencing the time series\n",
    "dtepts = tepts.diff(1)\n",
    "dtepts = dtepts.dropna()\n",
    "dtepts.name = 'dtep'\n",
    "\n",
    "# Plot the differenced time series\n",
    "plt.plot(dtepts, color='b')\n",
    "plt.title('Differenced Time Series')\n",
    "plt.show()\n",
    "\n",
    "# Plot ACF and PACF\n",
    "plot_acf(dtepts, lags=20)\n",
    "plt.show()\n",
    "plot_pacf(dtepts, lags=20)\n",
    "plt.show()\n",
    "\n",
    "# KPSS test for stationarity\n",
    "kpss_stat, p_value, lags, crit_values = kpss(dtepts, regression='c', nlags='auto')\n",
    "\n",
    "# Output the results of the KPSS test\n",
    "print(f'KPSS Statistic: {kpss_stat}')\n",
    "print(f'p-value: {p_value}')\n",
    "print(f'Lags: {lags}')\n",
    "print('Critical Values:', crit_values)\n",
    "if p_value < 0.05:\n",
    "    print(\"The series is likely non-stationary.\")\n",
    "else:\n",
    "    print(\"The series is likely stationary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175e1c86-5f81-4e14-91c4-0816f2c43022",
   "metadata": {},
   "source": [
    "### **Example 3: Chinese Quarterly GDP**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1a3178-610f-4b76-b88a-8a4747114dd6",
   "metadata": {},
   "source": [
    "In notebook C1, we found that the Chinese Quarterly GDP time series has time series has both trend and seasonality. Since it is the quarterly data, the number of seasons is 4 naturally. We therefore seasonally difference it with a lag of 4. After applying seasonal differencing with a lag of 4, we plot the seasonally differenced series to visualize the effects of removing seasonality. This transformation helped highlight trends without seasonal noise. Next, we performed a first difference on the seasonally differenced series to eliminate any remaining trend components. We then plotted this first differenced series and examine its ACF and PACF to assess the correlation structure, guiding our ARIMA model selection. We also conduct the KPSS test for stationarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ef31f0-18d2-4b30-b8af-f8007331fbd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "x = pd.read_csv(dtapath + 'gdpquarterlychina1992.1-2017.4.csv',header=0)\n",
    "dates = pd.date_range(start='1992',periods=len(x),freq='QE')\n",
    "x.index=dates\n",
    "\n",
    "# Plot the original time series\n",
    "x.plot()\n",
    "plt.title('Chinese Quarterly GDP 1992-2017')\n",
    "plt.ylabel('billions of RMB')\n",
    "plt.show()\n",
    "\n",
    "# Create a date range starting from 1992 with quarterly frequency\n",
    "dates = pd.date_range(start='1992', periods=len(x), freq='QE')\n",
    "x.index = dates\n",
    "\n",
    "# Create a time series from the 'GDP' column\n",
    "x = pd.Series(x['GDP'])\n",
    "\n",
    "# Seasonal differencing with lag 4\n",
    "dx = x.diff(4).dropna()\n",
    "\n",
    "# Plot the seasonally differenced series\n",
    "dx.plot(marker='o', ms=3)  # ms refers to marker size\n",
    "plt.title('Seasonally Differenced GDP (Lag 4)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Differenced GDP')\n",
    "plt.show()\n",
    "\n",
    "# First differencing the seasonally differenced series\n",
    "d1dx = dx.diff(1).dropna()\n",
    "\n",
    "# Plot the first difference of the seasonally differenced series\n",
    "d1dx.plot(marker='o', ms=3)\n",
    "plt.title('First Difference of Seasonally Differenced GDP')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Differenced GDP')\n",
    "plt.show()\n",
    "\n",
    "# Plot ACF and PACF for the first difference of seasonally differenced series\n",
    "plot_acf(d1dx, lags=44)\n",
    "plt.title('ACF of Differenced Series')\n",
    "plt.show()\n",
    "plot_pacf(d1dx, lags=44)\n",
    "plt.title('PACF of Differenced Series')\n",
    "plt.show()\n",
    "\n",
    "# KPSS test for stationarity\n",
    "kpss_stat, p_value, lags, crit_values = kpss(d1dx, regression='c', nlags='auto')\n",
    "\n",
    "# Output the results of the KPSS test\n",
    "print(f'KPSS Statistic: {kpss_stat}')\n",
    "print(f'p-value: {p_value}')\n",
    "print(f'Lags: {lags}')\n",
    "print('Critical Values:', crit_values)\n",
    "if p_value < 0.05:\n",
    "    print(\"The series is likely non-stationary.\")\n",
    "else:\n",
    "    print(\"The series is likely stationary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a4fae3-e6f2-449b-a7f6-b65a66313db0",
   "metadata": {},
   "source": [
    "### **Example 1 [continued]: The NAO Index Since January 1950**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e2ed77-c318-43d8-8b8b-1d1221adacef",
   "metadata": {},
   "source": [
    "**Exercise:** Conduct the KPSS test for stationarity on the NAO data (variable 'naots') with a maximum of 50 lags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157284d4-a110-48c9-9dea-49cd0b7f8f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bd430aa",
   "metadata": {},
   "source": [
    "## 5. Autoregressive Integrated Moving Average (ARIMA) Models\n",
    "\n",
    "ARIMA incorporates the concept of ARMA applied to a differenced series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55ba244-7699-4747-89eb-f433c4fc1b4d",
   "metadata": {},
   "source": [
    "### **Example 2 [continued]: Global Annual Mean Surface Air Temperature Changes Series (1880-1985)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beedc9f",
   "metadata": {},
   "source": [
    "### Choose model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296a8463-1691-4e15-a4ed-df13cefa0b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf = sm.tsa.arma_order_select_ic(dtepts, max_ar=3, max_ma=3, ic=['aic', 'bic', 'hqic'], trend='c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca77712-01a6-483e-8ddc-0b2d572e3381",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best AR term (p for minimum AIC):\", inf.aic_min_order[0])\n",
    "print(\"Best MA term (q for minimum AIC):\", inf.aic_min_order[1])\n",
    "\n",
    "print(\"Best AR term (p for minimum BIC):\", inf.bic_min_order[0])\n",
    "print(\"Best MA term (q for minimum BIC):\", inf.bic_min_order[1])\n",
    "\n",
    "print(\"Best AR term (p for minimum HQIC):\", inf.hqic_min_order[0])\n",
    "print(\"Best MA term (q for minimum HQIC):\", inf.hqic_min_order[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37b42ab-98ed-424a-9dd8-ddff54d6c469",
   "metadata": {},
   "source": [
    "AIC and HQIC derive (p,q) = (1,3) and BIC derives (p,q) = (1,1). We choose to fit and predict the ARMA(1,1) first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b2b021-e97d-44b3-9837-1ca522c18c0c",
   "metadata": {},
   "source": [
    "### Fit model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9766c68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arma11 = ARIMA(dtepts, order=(1,0,1)).fit()\n",
    "print(arma11.summary())\n",
    "\n",
    "# Analyze the residuals\n",
    "resid11 = arma11.resid\n",
    "\n",
    "# Plot ACF and PACF of the residuals\n",
    "plot_acf(resid11, lags=20)\n",
    "plt.show()\n",
    "plot_pacf(resid11, lags=20)\n",
    "plt.show()\n",
    "\n",
    "# Perform the Ljung-Box test for residuals\n",
    "    # Calculate Ljung-Box test statistics and p-values\n",
    "ljung_box_results = acorr_ljungbox(resid11, lags=20, return_df=True)\n",
    "    # Create a plot for the p-values\n",
    "plt.figure()\n",
    "plt.plot(ljung_box_results['lb_pvalue'], marker='o', linestyle='-', color='b')\n",
    "plt.axhline(y=0.05, color='r', linestyle='--')  # 5% significance level\n",
    "plt.title('Ljung-Box Test P-Values')\n",
    "plt.xlabel('Lags')\n",
    "plt.ylabel('P-Value')\n",
    "plt.xticks(np.arange(0, 21, 1))\n",
    "plt.xticks(ljung_box_results.index)  # Set x-ticks to all lags\n",
    "plt.gca().set_xticklabels([str(int(x)) if x % 2 == 0 else '' for x in ljung_box_results.index])\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Q-Q plot\n",
    "plt.figure()\n",
    "sm.qqplot(resid11, line='q', ax=plt.gca())\n",
    "plt.title('Q-Q Plot (Sample vs Theoretical Quantiles)')\n",
    "plt.grid()\n",
    "\n",
    "# Perform the normality test on residuals\n",
    "normaltest_result = stats.normaltest(resid11)\n",
    "print(\"Normality test result:\", normaltest_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617c1151-b9cd-49ca-a1ea-03a49a85c44a",
   "metadata": {},
   "source": [
    "The residual series behaves like a normal white noise, and so the estimated model fits very well to the differenced series data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e64390-f36c-40ff-b366-b608d6d77086",
   "metadata": {},
   "source": [
    "### Predict model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1198e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate prediction results\n",
    "pred = arma11.get_prediction(start='1960-12', end='1990-12')\n",
    "\n",
    "# Extract predicted mean and confidence intervals\n",
    "predicts = pred.predicted_mean\n",
    "predconf = pred.conf_int()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(dtepts, label='Observed', color='blue')\n",
    "predicts.plot(label='Forecast', color='red')\n",
    "plt.fill_between(predicts.index,\n",
    "                 predconf.iloc[:, 0],\n",
    "                 predconf.iloc[:, 1], color='gray', alpha=0.3, label='Confidence Interval')\n",
    "plt.title('ARIMA Forecast (1960-1990)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Differenced Temperature')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882ddfaf-0322-4782-ad2a-c19c547f5b6c",
   "metadata": {},
   "source": [
    "The forecasts — both in-sample and out-of-sample — generated by the fitted ARMA(1,1) model are not really satisfactory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dc8989-634d-414c-9715-c2ac58482482",
   "metadata": {},
   "source": [
    "**Exercise:** Fit and predict the ARMA(1,3) model and compare the results to the ARMA(1,3) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d27c76-d593-4b12-a07d-fca060de1072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd547542-f188-4924-b327-c1c650c98fa8",
   "metadata": {},
   "source": [
    "Manual differencing versus built-in differencing are two different pre-processing strategies for handling non-stationarity that can lead to different results as the following example demonstrates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dc175e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arima111 = ARIMA(tepts, order=(1,1,1)).fit()\n",
    "resid111 = arima111.resid\n",
    "\n",
    "# Plot ACF and PACF of the residuals\n",
    "plot_acf(resid111, lags=20)\n",
    "plt.show()\n",
    "plot_pacf(resid111, lags=20)\n",
    "plt.show()\n",
    "\n",
    "# Perform the Ljung-Box test for residuals\n",
    "    # Calculate Ljung-Box test statistics and p-values\n",
    "ljung_box_results = acorr_ljungbox(resid111, lags=20, return_df=True)\n",
    "    # Create a plot for the p-values\n",
    "plt.figure()\n",
    "plt.plot(ljung_box_results['lb_pvalue'], marker='o', linestyle='-', color='b')\n",
    "plt.axhline(y=0.05, color='r', linestyle='--')  # 5% significance level\n",
    "plt.title('Ljung-Box Test P-Values')\n",
    "plt.xlabel('Lags')\n",
    "plt.ylabel('P-Value')\n",
    "plt.xticks(np.arange(0, 21, 1))\n",
    "plt.xticks(ljung_box_results.index)  # Set x-ticks to all lags\n",
    "plt.gca().set_xticklabels([str(int(x)) if x % 2 == 0 else '' for x in ljung_box_results.index])\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Q-Q plot\n",
    "plt.figure()\n",
    "sm.qqplot(resid111, line='q', ax=plt.gca())\n",
    "plt.title('Q-Q Plot (Sample vs Theoretical Quantiles)')\n",
    "plt.grid()\n",
    "\n",
    "# Perform the normality test on residuals\n",
    "normaltest_result = stats.normaltest(resid111)\n",
    "print(\"Normality test result:\", normaltest_result)\n",
    "\n",
    "# Generate prediction results\n",
    "pred = arima111.get_prediction(start='1960-12', end='1990-12')\n",
    "\n",
    "# Extract predicted mean and confidence intervals\n",
    "predicts = pred.predicted_mean\n",
    "predconf = pred.conf_int()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(dtepts, label='Observed', color='blue')\n",
    "predicts.plot(label='Forecast', color='red')\n",
    "plt.fill_between(predicts.index,\n",
    "                 predconf.iloc[:, 0],\n",
    "                 predconf.iloc[:, 1], color='gray', alpha=0.3, label='Confidence Interval')\n",
    "plt.title('ARIMA Forecast (1960-1990)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Differenced Temperature')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74154bca-d0a7-4ab9-9365-a80b2bad76a4",
   "metadata": {},
   "source": [
    "Receive both in-sample predictions using `fittedvalues` and out-sample forecasts using `forecast`, directly in the original value scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b9111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "arima111 = ARIMA(tepts, order=(1,1,1)).fit()\n",
    "\n",
    "# Define out-sample forecast\n",
    "forecast_steps = 5\n",
    "forecast_series = arima111.forecast(steps=forecast_steps)\n",
    "last_date = tepts.index[-1]  # Get the last date of actual data\n",
    "forecast_dates = pd.date_range(start=last_date, periods=forecast_steps + 1, freq='A')[1:]\n",
    "forecast_result = arima111.get_forecast(steps=forecast_steps)\n",
    "forecast_series = forecast_result.predicted_mean\n",
    "forecast_conf = forecast_result.conf_int()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Temperature Anomaly')\n",
    "plt.plot(tepts.index, arima111.fittedvalues, color=\"red\", label=\"Fitted Values\")\n",
    "plt.plot(forecast_dates, forecast_series, color='black', label='Forecast Out-Sample')\n",
    "tepts.plot(color=\"blue\", label=\"Observed\")\n",
    "plt.fill_between(forecast_dates,\n",
    "                 forecast_conf.iloc[:, 0],  # Lower confidence interval\n",
    "                 forecast_conf.iloc[:, 1],  # Upper confidence interval\n",
    "                 color='gray', alpha=0.3, label='Confidence Interval')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473ed4ed-1bf9-4f73-a0b3-fa340bd8e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "arima113 = ARIMA(tepts, order=(1,1,3)).fit()\n",
    "\n",
    "# Define out-sample forecast\n",
    "forecast_steps = 5\n",
    "forecast_series = arima113.forecast(steps=forecast_steps)\n",
    "last_date = tepts.index[-1]  # Get the last date of actual data\n",
    "forecast_dates = pd.date_range(start=last_date, periods=forecast_steps + 1, freq='A')[1:]\n",
    "forecast_result = arima113.get_forecast(steps=forecast_steps)\n",
    "forecast_series = forecast_result.predicted_mean\n",
    "forecast_conf = forecast_result.conf_int()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Temperature Anomaly')\n",
    "plt.plot(tepts.index, arima113.fittedvalues, color=\"red\", label=\"Fitted Values\")\n",
    "plt.plot(forecast_dates, forecast_series, color='black', label='Forecast Out-Sample')\n",
    "tepts.plot(color=\"blue\", label=\"Observed\")\n",
    "plt.fill_between(forecast_dates,\n",
    "                 forecast_conf.iloc[:, 0],  # Lower confidence interval\n",
    "                 forecast_conf.iloc[:, 1],  # Upper confidence interval\n",
    "                 color='gray', alpha=0.3, label='Confidence Interval')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fd5304-4f77-458a-849e-63306ba37306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
